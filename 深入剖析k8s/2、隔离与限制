Linux Cgroups 就是 Linux 内核中用来为进程设置资源限制的一个重要功能，最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等

在 Linux 中，Cgroups 给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的 /sys/fs/cgroup 路径下
在 Ubuntu 16.04 机器里，我可以用 mount指令把它们展示出来，这条命令是：
  $ mount -t cgroup cpuset on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)
  cpu on /sys/fs/cgroup/cpu type cgroup (rw,nosuid,nodev,noexec,relatime,cpu)
  cpuacct on /sys/fs/cgroup/cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct)
  blkio on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)
  memory on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)
  ...

Linux Cgroups的限制方法：
在 /sys/fs/cgroup 下面有很多诸如 cpuset、cpu、 memory 这样的子目录，也叫子系统
这些都是我这台机器当前可以被 Cgroups 进行限制的资源种类，而在子系统对应的资源种类下，你就可以看到该类资源具体可以被限制的方法，比如对 CPU 子系统来说，我们就可以看到如下几个配置文件，这个指令是：
  $ ls /sys/fs/cgroup/cpu
  cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us  cpu.shares notify_on_release
  cgroup.procs      cpu.cfs_quota_us  cpu.rt_runtime_us cpu.stat  tasks
而这样的配置文件又如何使用呢？需要在对应的子系统下面创建一个目录，比如docker服务会在为每个容器在/sys/fs/cgroup/cpu/docker/下创建一个专属目录，该目录下会自动生成该子系统对应的资源限制文件
  #ls /sys/fs/cgroup/cpu/docker/33b62737dff1792b2f6b4a52bd95857a97e2a6b2fd3279624d2e24966646ab33
  cgroup.clone_children  cpuacct.sched_cfs_statistics       cpuacct.usage         cpu.rt_period_us      cpuset.mem_hardwall        cpuset.mems                      cpuset.trick_tasks
  cgroup.event_control   cpuacct.sched_lat_histgram_cfs     cpuacct.usage_percpu  cpu.rt_runtime_us     cpuset.memory_migrate      cpuset.sched_load_balance        cpu.shares
  cgroup.procs           cpuacct.sched_lat_histgram_enable  cpu.bvt_warp_ns       cpuset.cpu_exclusive  cpuset.memory_pressure     cpuset.sched_relax_domain_level  cpu.stat
  cpuacct.proc_stat      cpuacct.sched_lat_histgram_rt      cpu.cfs_period_us     cpuset.cpus           cpuset.memory_spread_page  cpuset.trick_cpus                notify_on_release
  cpuacct.proc_stat_v2   cpuacct.stat                       cpu.cfs_quota_us      cpuset.mem_exclusive  cpuset.memory_spread_slab  cpuset.trick_exempt_tasks        tasks
  
  ## cpu.cfs_quota_us文件即该容器被分配到总量为 cfs_quota 的 CPU 时间
  ## task文件即被限制的进程id集合
  #cat /sys/fs/cgroup/cpu/docker/33b62737dff1792b2f6b4a52bd95857a97e2a6b2fd3279624d2e24966646ab33/tasks
  73147
  73179
  73182
  73184
  73185
  73246
  73340
  73341
  73342
  73355
除 CPU 子系统外，Cgroups 的每一项子系统都有其独有的资源限制能力，比如：
  blkio，为 块 设 备 设 定 I/O 限 制，一般用于磁盘等设备；
  cpuset，为进程分配单独的 CPU 核和对应的内存节点；
  memory，为进程设定内存使用的限制
  
Linux Cgroups 的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合
而对于 Docker 等 Linux 容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了  
而至于在这些控制组下面的资源文件里填上什么值，就靠用户执行 docker run 时的参数指定了

通过以上讲述，你现在应该能够理解，一个正在运行的 Docker 容器，其实就是一个启用了多个 Linux Namespace 的应用进程
而这个进程能够使用的资源量，则受 Cgroups 配置的限制。这也是容器技术中一个非常重要的概念，即：容器是一个“单进程”模型

缺陷：
跟 Namespace 的情况类似，Cgroups 对资源的限制能力也有很多不完善的地方，被提及最多的自然是 /proc 文件系统的问题
众所周知，Linux 下的 /proc 目录存储的是记录当前内核运行状态的一系列特殊文件，用户可以通过访问这些文件，查看系统以及当前正在运行的进程的信息，比如 CPU 使用情况、内存占用率等，这些文件也是 top 指令查看系统信息的主要数据来源
但是，你如果在容器里执行 top 指令，就会发现，它显示的信息居然是宿主机的 CPU 和内存数据，而不是当前容器的数据
造成这个问题的原因就是，/proc 文件系统并不知道用户通过 Cgroups 给这个容器做了什么样的资源限制，即：/proc 文件系统不了解 Cgroups 限制的存在
解决方法：
lxcfs，通过文件挂载的方式，把cgroup中关于系统的相关信息读取出来，通过docker的volume挂载给容器内部的proc系统
lxcfs 内存使用架构图：
当我们把宿主机的 /var/lib/lxcfs/proc/memoinfo 文件挂载到Docker容器的/proc/meminfo位置后，容器中进程读取相应文件内容时，LXCFS的FUSE实现会从容器对应的Cgroup中读取正确的内存限制，从而使得应用获得正确的资源约束设定

  
