什么是HADOOP？
答：Hadoop 是 Apache 下的一个开源项目，涵盖了各个大数据组件，各组件又各司其责共同支撑起了HADOOP这个大数据生态圈

HADOOP生态圈常见软件及应用场景
--------------------------------------------------------------------------
                Ambari（安装部署、监控工具）
--------------------------------------------------------------------------
| Z   |     |               Oozie（任务调度系统）                  
| o   |  H  |--------------------------------------------------------------   
| o   |  B  |           Hive  Pig   Hive2   Pig2                  |       |
| k   |  A  |-----------------------------------------------------| sqoop |
| e   |  S  | MapReduce（离线计算） TEZ（DAG计算）  Spark（内存计算    |       |
| e   |  E  |-------------------------------------------------------------
| p   |     |                YARN（分布式计算框架)                   |       |
| e   |-----------------------------------------------------------| Flume |
| r   |                      HDFS（分布式存储系统）                 |       |
|     |-----------------------------------------------------------|       |
Zookeeper：分布式协调服务
HBASE：分布式数据库
sqoop：ETL工具
Flume：日志收集
可以看出，Hadoop 的基础是 HDFS 和 Yarn，在此基础上有各种计算模型，如 MapReduce、Spark、HBase 等；
而在计算模型上层，对应的是各种分布式计算辅助工具，如 Hive、Pig、Sqoop 等。此外，还有分布式协作工作 ZooKeeper 以及日志收集工具 Flume，这么多工具如何协作使用呢？这就是任务调度层 Oozie 的存在价值，它负责协调任务的有序执行。
最顶层是 Hadoop 整个生态圈的统一管理工具，Ambari 可以为 Hadoop 以及相关大数据软件使用提供更多便利

简单介绍经典的HADOOP组件
答：1）数据存储：HDFS，一个分布式文件系统，此文件系统的主要特征是数据分散存储，一个文件存储在 HDFS 上时会被分成若干个数据块，每个数据块分别存储在不同的服务器上
2）数据分析：MapReduce 计算引擎，何为计算引擎？“多台服务器并行处理，那么就要考虑如何分配计算任务到多台机器。如果一台机器挂了，该如何重新启动相应的分析任务，以及机器之间如何互相通信、交换数据以完成复杂的计算等，这一过程的实现称为计算引擎”
MapReduce 主要分为两阶段：Map 阶段和 Reducer 阶段，Map就是将一个大任务拆分成多个小任务在多台机器上分散进行，Reducer就是将各小任务的结果汇总成最终结果
HADOOP有多种计算引擎，MapReduce 是第一代计算引擎，Tez 和 Spark 是第二代
3）Yarn：分布式资源管理器，在YARN中，支持CPU和内存两种资源管理，资源管理由ResourceManager（RM）、ApplicationMaster（AM）和NodeManager（NM）共同完成。
其中，RM负责对各个NM上的资源进行统一管理和调度。而NodeManager则负责资源的供给和隔离。当用户提交一个应用程序时，会创建一个用以跟踪和管理这个程序的AM，它负责向RM申请资源，并要求NM启动指定资源的任务。这就是YARN的基本运行机制
Yarn 作为一个通用的分布式资源管理器，它可以管理多种计算模型，如 Spark、Storm、MapReduce 、Flink 等都可以放到 Yarn 下进行统一管理
4）Spark：内存计算，以内存换效率，相比于MapReduce 产生的中间结果会保存在磁盘上下次操作再调到内存中这种读成本高效率低下 不同的是，Spark在中间过程中不会落盘，所有任务都完成之后最终才写入磁盘
5）HBASE：分布式列存储数据库，了结HBASE之前我们首先要了结何为 面向行存储和面向列存储
面向行存储：数据按行存储，对inster和update友好，主要适合于事务性要求严格的场合，但是对select不友好，首先对于未建立索引的表select时会进行全表扫描，建立索引也会话费大量时间和资源，同时在读取部分字段（非select *）时由于需要来回切换处理不同的数据类型进行数据分析导致效率大打折扣
面向列存储：数据按列存储，每一列单独存放，由于数据类型一直所以压缩效率高，同时数据即索引，最大优点是查询速度快，这对数据完整性要求不高的大数据处理领域犹为重要，但是在写入时的性能不如面向行存储，因为需要对数据进行拆分再写入，意味着磁头调度次数更多，花费对时间也就更多
Hbase继承了列存储的特性，它非常适合需对数据进行随机读、写操作、比如每秒对PB级数据进行几千次读、写访问是非常简单的操作。 其次，Hbase构建在HDFS之上，其内部管理的文件全部存储在HDFS中。这使它具有高度容错性和可扩展性，并支持Hadoop Mapreduce程序设计模型
6）Hive：数据仓库，Hive 定义了一种类似 SQL 的查询语言（HQL），它可以将 SQL 转化为 MapReduce 任务在 Hadoop 上执行，因此，哪怕你不熟悉 MapReduce 程序，只要会写标准的 SQL 语句，也能对 HDFS 上的海量数据进行分析和计算
7）Oozie：工作流调度器

