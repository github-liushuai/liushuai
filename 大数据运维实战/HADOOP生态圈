什么是HADOOP？
答：Hadoop 是 Apache 下的一个开源项目，涵盖了各个大数据组件，各组件又各司其责共同支撑起了HADOOP这个大数据生态圈

HADOOP生态圈常见软件及应用场景
--------------------------------------------------------------------------
                Ambari（安装部署、监控工具）
--------------------------------------------------------------------------
| Z   |     |               Oozie（任务调度系统）                  
| o   |  H  |--------------------------------------------------------------   
| o   |  B  |           Hive  Pig   Hive2   Pig2                  |       |
| k   |  A  |-----------------------------------------------------| sqoop |
| e   |  S  | MapReduce（离线计算） TEZ（DAG计算）  Spark（内存计算    |       |
| e   |  E  |-------------------------------------------------------------
| p   |     |                YARN（分布式计算框架)                   |       |
| e   |-----------------------------------------------------------| Flume |
| r   |                      HDFS（分布式存储系统）                 |       |
|     |-----------------------------------------------------------|       |
Zookeeper：分布式协调服务
HBASE：分布式数据库
sqoop：ETL工具
Flume：日志收集
可以看出，Hadoop 的基础是 HDFS 和 Yarn，在此基础上有各种计算模型，如 MapReduce、Spark、HBase 等；
而在计算模型上层，对应的是各种分布式计算辅助工具，如 Hive、Pig、Sqoop 等。此外，还有分布式协作工作 ZooKeeper 以及日志收集工具 Flume，这么多工具如何协作使用呢？这就是任务调度层 Oozie 的存在价值，它负责协调任务的有序执行。
最顶层是 Hadoop 整个生态圈的统一管理工具，Ambari 可以为 Hadoop 以及相关大数据软件使用提供更多便利

简单介绍经典的HADOOP组件
答：1）数据存储：HDFS，一个分布式文件系统，此文件系统的主要特征是数据分散存储，一个文件存储在 HDFS 上时会被分成若干个数据块，每个数据块分别存储在不同的服务器上
2）数据分析：MapReduce 计算引擎，何为计算引擎？“多台服务器并行处理，那么就要考虑如何分配计算任务到多台机器。如果一台机器挂了，该如何重新启动相应的分析任务，以及机器之间如何互相通信、交换数据以完成复杂的计算等，这一过程的实现称为计算引擎”
MapReduce 主要分为两阶段：Map 阶段和 Reducer 阶段，Map就是将一个大任务拆分成多个小任务在多台机器上分散进行，Reducer就是将各小任务的结果汇总成最终结果
HADOOP有多种计算引擎，MapReduce 是第一代计算引擎，Tez 和 Spark 是第二代
3）Yarn：分布式资源管理器，在YARN中，支持CPU和内存两种资源管理，资源管理由ResourceManager（RM）、ApplicationMaster（AM）和NodeManager（NM）共同完成。
其中，RM负责对各个NM上的资源进行统一管理和调度。而NodeManager则负责资源的供给和隔离。当用户提交一个应用程序时，会创建一个用以跟踪和管理这个程序的AM，它负责向RM申请资源，并要求NM启动指定资源的任务。这就是YARN的基本运行机制
Yarn 作为一个通用的分布式资源管理器，它可以管理多种计算模型，如 Spark、Storm、MapReduce 、Flink 等都可以放到 Yarn 下进行统一管理
4）Spark：内存计算，以内存换效率，相比于MapReduce 产生的中间结果会保存在磁盘上下次操作再调到内存中这种读成本高效率低下 不同的是，Spark在中间过程中不会落盘，所有任务都完成之后最终才写入磁盘
5）HBASE：分布式列存储数据库，了结HBASE之前我们首先要了结何为 面向行存储和面向列存储
面向行存储：数据按行存储，对inster和update友好，主要适合于事务性要求严格的场合，但是对select不友好，首先对于未建立索引的表select时会进行全表扫描，建立索引也会话费大量时间和资源，同时在读取部分字段（非select *）时由于需要来回切换处理不同的数据类型进行数据分析导致效率大打折扣
面向列存储：数据按列存储，每一列单独存放，由于数据类型一直所以压缩效率高，同时数据即索引，最大优点是查询速度快，这对数据完整性要求不高的大数据处理领域犹为重要，但是在写入时的性能不如面向行存储，因为需要对数据进行拆分再写入，意味着磁头调度次数更多，花费对时间也就更多
Hbase继承了列存储的特性，它非常适合需对数据进行随机读、写操作、比如每秒对PB级数据进行几千次读、写访问是非常简单的操作。 其次，Hbase构建在HDFS之上，其内部管理的文件全部存储在HDFS中。这使它具有高度容错性和可扩展性，并支持Hadoop Mapreduce程序设计模型
6）Hive：数据仓库，Hive 定义了一种类似 SQL 的查询语言（HQL），它可以将 SQL 转化为 MapReduce 任务在 Hadoop 上执行，因此，哪怕你不熟悉 MapReduce 程序，只要会写标准的 SQL 语句，也能对 HDFS 上的海量数据进行分析和计算
7）Oozie：是一个基于工作流引擎的调度器，可以实现多个任务的依赖性，Oozie 工作流通过 hPDL 定义（hPDL 是一种 XML 的流程定义语言），工作流操作通过远程系统启动任务。当任务完成后，远程系统会进行回调来通知任务已经结束，然后再开始下一个操作
8）Sqoop：SQL-to-Hadoop，主要用于传统数据库和 Hadoop 之间传输数据
9）Pig：与Hive 类似，它定义了一种数据流语言，即 Pig Latin，它是 MapReduce 编程的复杂性的抽象，Pig Latin 可以完成排序、过滤、求和、关联等操作，支持自定义函数。Pig 自动把 Pig Latin 映射为 MapReduce 作业，上传到集群运行，减少用户编写 Java 程序的苦恼
10）Flume：日志收集工具，将数据从产生、传输、处理并最终写入目标路径的过程抽象为数据流，在具体的数据流中，数据源支持在 Flume 中定制数据发送方，从而支持收集各种不同协议数据，在 Hadoop 平台，我们主要使用的是通过 Flume 将数据从源服务器写入 Hadoop 的 HDFS 上
11）Kafka：分布式消息队列，消息生产者和消息消费者的中间缓存，实现解耦合的作用，在产生大量消息时能保证系统有条不紊的进行下去
12）ZooKeeper：分布式协作服务，主要用于选举
13）Ambari：大数据运维工具，是一个大数据基础运维平台，它实现了 Hadoop 生态圈各种组件的自动化部署、服务管理和监控告警，Ambari 通过 puppet 实现自动化安装和配置，通过 Ganglia 收集监控度量指标，用 Nagios 实现故障报警，目前指出大多数HADOOP组件

简单描述下啊HDFS的工作原理


