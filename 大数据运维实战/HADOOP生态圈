什么是HADOOP？
答：Hadoop 是 Apache 下的一个开源项目，涵盖了各个大数据组件，各组件又各司其责共同支撑起了HADOOP这个大数据生态圈

HADOOP生态圈常见软件及应用场景
--------------------------------------------------------------------------
                Ambari（安装部署、监控工具）
--------------------------------------------------------------------------
| Z   |     |               Oozie（任务调度系统）                  
| o   |  H  |--------------------------------------------------------------   
| o   |  B  |           Hive  Pig   Hive2   Pig2                  |       |
| k   |  A  |-----------------------------------------------------| sqoop |
| e   |  S  | MapReduce（离线计算） TEZ（DAG计算）  Spark（内存计算    |       |
| e   |  E  |-------------------------------------------------------------
| p   |     |                YARN（分布式计算框架)                   |       |
| e   |-----------------------------------------------------------| Flume |
| r   |                      HDFS（分布式存储系统）                 |       |
|     |-----------------------------------------------------------|       |
Zookeeper：分布式协调服务
HBASE：分布式数据库
sqoop：ETL工具
Flume：日志收集
可以看出，Hadoop 的基础是 HDFS 和 Yarn，在此基础上有各种计算模型，如 MapReduce、Spark、HBase 等；
而在计算模型上层，对应的是各种分布式计算辅助工具，如 Hive、Pig、Sqoop 等。此外，还有分布式协作工作 ZooKeeper 以及日志收集工具 Flume，这么多工具如何协作使用呢？这就是任务调度层 Oozie 的存在价值，它负责协调任务的有序执行。
最顶层是 Hadoop 整个生态圈的统一管理工具，Ambari 可以为 Hadoop 以及相关大数据软件使用提供更多便利

简单介绍经典的HADOOP组件
答：1）数据存储：HDFS，一个分布式文件系统，此文件系统的主要特征是数据分散存储，一个文件存储在 HDFS 上时会被分成若干个数据块，每个数据块分别存储在不同的服务器上
2）数据分析：MapReduce 计算引擎，何为计算引擎？“多台服务器并行处理，那么就要考虑如何分配计算任务到多台机器。如果一台机器挂了，该如何重新启动相应的分析任务，以及机器之间如何互相通信、交换数据以完成复杂的计算等，这一过程的实现称为计算引擎”
MapReduce 主要分为两阶段：Map 阶段和 Reducer 阶段，Map就是将一个大任务拆分成多个小任务在多台机器上分散进行，Reducer就是将各小任务的结果汇总成最终结果
HADOOP有多种计算引擎，MapReduce 是第一代计算引擎，Tez 和 Spark 是第二代
3）Yarn：分布式资源管理器，在YARN中，支持CPU和内存两种资源管理，资源管理由ResourceManager（RM）、ApplicationMaster（AM）和NodeManager（NM）共同完成。
其中，RM负责对各个NM上的资源进行统一管理和调度。而NodeManager则负责资源的供给和隔离。当用户提交一个应用程序时，会创建一个用以跟踪和管理这个程序的AM，它负责向RM申请资源，并要求NM启动指定资源的任务。这就是YARN的基本运行机制
Yarn 作为一个通用的分布式资源管理器，它可以管理多种计算模型，如 Spark、Storm、MapReduce 、Flink 等都可以放到 Yarn 下进行统一管理
4）Spark：内存计算，以内存换效率，相比于MapReduce 产生的中间结果会保存在磁盘上下次操作再调到内存中这种读成本高效率低下 不同的是，Spark在中间过程中不会落盘，所有任务都完成之后最终才写入磁盘
5）HBASE：分布式列存储数据库
